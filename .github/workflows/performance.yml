name: Performance Testing

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run performance tests daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:

permissions:
  contents: read

jobs:
  performance-benchmarks:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install psutil
          pip install -r requirements.txt

      - name: Run SFMGraph performance tests
        run: |
          pytest tests/test_sfm_service.py::TestSFMServicePerformance -v

      - name: Run memory efficiency tests
        run: |
          python -m pytest tests/test_sfm_service.py::TestSFMServicePerformance::test_large_graph_performance -v

      - name: Generate performance summary
        run: |
          echo "Performance test results for SFMGraph" > performance-results.txt
          echo "=====================================" >> performance-results.txt
          echo "Date: $(date)" >> performance-results.txt
          echo "Tests completed successfully" >> performance-results.txt

      - name: Upload performance reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-reports
          path: |
            performance-results.txt

  lookup-speed-benchmarks:
    name: Lookup Speed Benchmarks
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Create lookup test file
        run: |
          cat > lookup_tests.py << 'EOF'
          import pytest
          import time
          from core.sfm_service import SFMService, SFMServiceConfig, CreateActorRequest, CreateRelationshipRequest
          from core.sfm_enums import RelationshipKind
          from core.security_validators import disable_validation_rate_limiting, enable_validation_rate_limiting

          class TestLookupPerformance:
              def setup_method(self):
                  # Disable rate limiting for performance tests
                  disable_validation_rate_limiting()
                  
                  config = SFMServiceConfig(storage_backend="test", enable_logging=False)
                  self.service = SFMService(config)
                  
                  # Create test data
                  self.actors = []
                  for i in range(10):  # Reduced size for simple testing
                      actor = self.service.create_actor(CreateActorRequest(
                          name=f"Test Actor {i}",
                          description=f"Test actor {i}",
                          sector="test"
                      ))
                      self.actors.append(actor)
                      
                  # Create relationships
                  for i in range(5):
                      if i < len(self.actors) - 1:
                          self.service.create_relationship(CreateRelationshipRequest(
                              source_id=self.actors[i].id,
                              target_id=self.actors[i + 1].id,
                              kind=RelationshipKind.AFFECTS
                          ))

              def teardown_method(self):
                  # Re-enable rate limiting after tests
                  enable_validation_rate_limiting()

              def test_node_lookup_by_id(self):
                  start_time = time.time()
                  result = self.service.get_node_by_id(self.actors[5].id)
                  end_time = time.time()
                  assert result is not None
                  print(f"Node lookup took {end_time - start_time:.4f} seconds")

              def test_node_search_by_name(self):
                  start_time = time.time()
                  result = self.service.search_nodes("Test Actor 5")
                  end_time = time.time()
                  assert len(result) > 0
                  print(f"Node search took {end_time - start_time:.4f} seconds")

              def test_relationship_lookup(self):
                  start_time = time.time()
                  result = self.service.get_relationships(self.actors[0].id)
                  end_time = time.time()
                  assert len(result) >= 0
                  print(f"Relationship lookup took {end_time - start_time:.4f} seconds")

              def test_statistics_calculation(self):
                  start_time = time.time()
                  result = self.service.get_statistics()
                  end_time = time.time()
                  assert result.total_nodes == 10
                  print(f"Statistics calculation took {end_time - start_time:.4f} seconds")
          EOF

      - name: Run lookup performance tests
        run: |
          pytest lookup_tests.py -v -s

      - name: Upload lookup test results
        uses: actions/upload-artifact@v4
        with:
          name: lookup-performance
          path: lookup_tests.py

  concurrent-performance:
    name: Concurrent Operations Performance
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run concurrent performance tests
        run: |
          pytest tests/test_sfm_service.py::TestSFMServicePerformance::test_concurrent_operations -v \
                 --tb=short

      - name: Generate performance summary
        run: |
          echo "Performance Test Summary" > performance-summary.txt
          echo "======================" >> performance-summary.txt
          echo "Date: $(date)" >> performance-summary.txt
          echo "Python Version: $(python --version)" >> performance-summary.txt
          echo "System: $(uname -a)" >> performance-summary.txt
          echo "" >> performance-summary.txt
          echo "Test Results:" >> performance-summary.txt
          echo "- SFMGraph Performance Tests: COMPLETED" >> performance-summary.txt
          echo "- Lookup Speed Benchmarks: COMPLETED" >> performance-summary.txt
          echo "- Concurrent Operations: COMPLETED" >> performance-summary.txt

      - name: Upload performance summary
        uses: actions/upload-artifact@v4
        with:
          name: performance-summary
          path: performance-summary.txt